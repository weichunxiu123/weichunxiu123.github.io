<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="utf-8">
    
    <title>Spark-standalone环境部署 | Hexo</title>
    
    
        <meta name="keywords" content="Spark-standalone环境部署">
    
    <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
    <meta name="description" content="spark（StandAlone环境部署）（一）、集群规划：选择三台机器分别为node1、node2、node3来组成集群环境。 其中node1上安装master和worker进程；node2上安装worker进程；node3上安装worker进程。 （二）、anaconda on linux安装过程： （1）前提：在linux服务器node1、node2、node3上都安装python(anac">
<meta property="og:type" content="article">
<meta property="og:title" content="Spark-standalone环境部署">
<meta property="og:url" content="http://example.com/wiki/Spark-standalone%E7%8E%AF%E5%A2%83%E9%83%A8%E7%BD%B2/index.html">
<meta property="og:site_name" content="Hexo">
<meta property="og:description" content="spark（StandAlone环境部署）（一）、集群规划：选择三台机器分别为node1、node2、node3来组成集群环境。 其中node1上安装master和worker进程；node2上安装worker进程；node3上安装worker进程。 （二）、anaconda on linux安装过程： （1）前提：在linux服务器node1、node2、node3上都安装python(anac">
<meta property="og:locale" content="en_US">
<meta property="og:image" content="http://example.com/wiki/Spark-standalone%E7%8E%AF%E5%A2%83%E9%83%A8%E7%BD%B2/wps1.jpg">
<meta property="og:image" content="http://example.com/wiki/Spark-standalone%E7%8E%AF%E5%A2%83%E9%83%A8%E7%BD%B2/wps2.jpg">
<meta property="og:image" content="http://example.com/wiki/Spark-standalone%E7%8E%AF%E5%A2%83%E9%83%A8%E7%BD%B2/wps3.jpg">
<meta property="og:image" content="http://example.com/wiki/Spark-standalone%E7%8E%AF%E5%A2%83%E9%83%A8%E7%BD%B2/wps4.jpg">
<meta property="og:image" content="http://example.com/wiki/Spark-standalone%E7%8E%AF%E5%A2%83%E9%83%A8%E7%BD%B2/wps5.jpg">
<meta property="og:image" content="http://example.com/wiki/Spark-standalone%E7%8E%AF%E5%A2%83%E9%83%A8%E7%BD%B2/wps6.jpg">
<meta property="og:image" content="http://example.com/wiki/Spark-standalone%E7%8E%AF%E5%A2%83%E9%83%A8%E7%BD%B2/wps7.jpg">
<meta property="og:image" content="http://example.com/wiki/Spark-standalone%E7%8E%AF%E5%A2%83%E9%83%A8%E7%BD%B2/wps8.jpg">
<meta property="og:image" content="http://example.com/wiki/Spark-standalone%E7%8E%AF%E5%A2%83%E9%83%A8%E7%BD%B2/wps9.jpg">
<meta property="og:image" content="http://example.com/wiki/Spark-standalone%E7%8E%AF%E5%A2%83%E9%83%A8%E7%BD%B2/wps10.jpg">
<meta property="og:image" content="http://example.com/wiki/Spark-standalone%E7%8E%AF%E5%A2%83%E9%83%A8%E7%BD%B2/wps11.jpg">
<meta property="og:image" content="http://example.com/wiki/Spark-standalone%E7%8E%AF%E5%A2%83%E9%83%A8%E7%BD%B2/wps12.jpg">
<meta property="og:image" content="http://example.com/wiki/Spark-standalone%E7%8E%AF%E5%A2%83%E9%83%A8%E7%BD%B2/wps13.jpg">
<meta property="og:image" content="http://example.com/wiki/Spark-standalone%E7%8E%AF%E5%A2%83%E9%83%A8%E7%BD%B2/wps14.jpg">
<meta property="og:image" content="http://example.com/wiki/Spark-standalone%E7%8E%AF%E5%A2%83%E9%83%A8%E7%BD%B2/wps15.jpg">
<meta property="og:image" content="http://example.com/wiki/Spark-standalone%E7%8E%AF%E5%A2%83%E9%83%A8%E7%BD%B2/wps16.jpg">
<meta property="og:image" content="http://example.com/wiki/Spark-standalone%E7%8E%AF%E5%A2%83%E9%83%A8%E7%BD%B2/wps17.jpg">
<meta property="og:image" content="http://example.com/wiki/Spark-standalone%E7%8E%AF%E5%A2%83%E9%83%A8%E7%BD%B2/wps18.jpg">
<meta property="og:image" content="http://example.com/wiki/Spark-standalone%E7%8E%AF%E5%A2%83%E9%83%A8%E7%BD%B2/wps19.jpg">
<meta property="og:image" content="http://example.com/wiki/Spark-standalone%E7%8E%AF%E5%A2%83%E9%83%A8%E7%BD%B2/wps20.jpg">
<meta property="og:image" content="http://example.com/wiki/Spark-standalone%E7%8E%AF%E5%A2%83%E9%83%A8%E7%BD%B2/wps21.jpg">
<meta property="og:image" content="http://example.com/wiki/Spark-standalone%E7%8E%AF%E5%A2%83%E9%83%A8%E7%BD%B2/wps22.jpg">
<meta property="article:published_time" content="2023-06-08T01:56:46.000Z">
<meta property="article:modified_time" content="2023-06-08T02:23:25.606Z">
<meta property="article:author" content="John Doe">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="http://example.com/wiki/Spark-standalone%E7%8E%AF%E5%A2%83%E9%83%A8%E7%BD%B2/wps1.jpg">
    

    
        <link rel="alternate" href="/atom.xml" title="Hexo" type="application/atom+xml">
    

    
        <link rel="icon" href="/favicon.ico">
    

    
<link rel="stylesheet" href="/libs/font-awesome/css/font-awesome.min.css">

    
<link rel="stylesheet" href="/libs/open-sans/styles.css">

    
<link rel="stylesheet" href="/libs/source-code-pro/styles.css">


    
<link rel="stylesheet" href="/css/style.css">

    
<script src="/libs/jquery/2.1.3/jquery.min.js"></script>

    
<script src="/libs/jquery/plugins/cookie/1.4.1/jquery.cookie.js"></script>

    
    
        
<link rel="stylesheet" href="/libs/lightgallery/css/lightgallery.min.css">

    
    
        
<link rel="stylesheet" href="/libs/justified-gallery/justifiedGallery.min.css">

    
    
    
    


    
        <script async src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>
    
<meta name="generator" content="Hexo 6.3.0"></head>

<body>
    <div id="container">
        <header id="header">
    <div id="header-main" class="header-inner">
        <div class="outer">
            <a href="/" id="logo">
                <i class="logo"></i>
                <span class="site-title">Hexo</span>
            </a>
            <nav id="main-nav">
                
                    <a class="main-nav-link" href="/">首页</a>
                
                    <a class="main-nav-link" href="/archives">归档</a>
                
                    <a class="main-nav-link" href="/categories">分类</a>
                
                    <a class="main-nav-link" href="/tags">标签</a>
                
                    <a class="main-nav-link" href="/about">关于</a>
                
            </nav>
            
            <div id="search-form-wrap">

    <form class="search-form">
        <input type="text" class="ins-search-input search-form-input" placeholder="Search">
        <button type="submit" class="search-form-submit"></button>
    </form>
    <div class="ins-search">
    <div class="ins-search-mask"></div>
    <div class="ins-search-container">
        <div class="ins-input-wrapper">
            <input type="text" class="ins-search-input" placeholder="Type something...">
            <span class="ins-close ins-selectable"><i class="fa fa-times-circle"></i></span>
        </div>
        <div class="ins-section-wrapper">
            <div class="ins-section-container"></div>
        </div>
    </div>
</div>
<script>
(function (window) {
    var INSIGHT_CONFIG = {
        TRANSLATION: {
            POSTS: 'Posts',
            PAGES: 'Pages',
            CATEGORIES: 'Categories',
            TAGS: 'Tags',
            UNTITLED: '(Untitled)',
        },
        ROOT_URL: '/',
        CONTENT_URL: '/content.json',
    };
    window.INSIGHT_CONFIG = INSIGHT_CONFIG;
})(window);
</script>

<script src="/js/insight.js"></script>


</div>
        </div>
    </div>
    <div id="main-nav-mobile" class="header-sub header-inner">
        <table class="menu outer">
            <tr>
                
                    <td><a class="main-nav-link" href="/">首页</a></td>
                
                    <td><a class="main-nav-link" href="/archives">归档</a></td>
                
                    <td><a class="main-nav-link" href="/categories">分类</a></td>
                
                    <td><a class="main-nav-link" href="/tags">标签</a></td>
                
                    <td><a class="main-nav-link" href="/about">关于</a></td>
                
                <td>
                    
    <div class="search-form">
        <input type="text" class="ins-search-input search-form-input" placeholder="Search">
    </div>

                </td>
            </tr>
        </table>
    </div>
</header>

        <div class="outer">
            
            
                <aside id="sidebar">
   
        
    
    <div id="toTop" class="fa fa-angle-up"></div>
</aside>
            
            <section id="main"><article id="post-Spark-standalone环境部署" class="article article-type-post" itemscope itemprop="blogPost">
    <div class="article-inner">
        
        
            <header class="article-header">
                
                    <div class="article-meta">
                        
                        
                        
    <div class="article-date">
        <i class="fa fa-calendar"></i>
        <a href="/wiki/Spark-standalone%E7%8E%AF%E5%A2%83%E9%83%A8%E7%BD%B2/">
            <time datetime="2023-06-08T01:56:46.000Z" itemprop="datePublished">2023-06-08</time>
        </a>
    </div>


                        
                            <i class="fa fa-bar-chart"></i>
                            <span id="busuanzi_container_site_pv"><span id="busuanzi_value_page_pv"></span></span>    
                        
                        
                            <div class="article-meta-button">
                                <a target="_blank" rel="external nofollow noopener noreferrer" href="https://github.com/weichunxiu123/git@github.com:weichunxiu123/weichunxiu123.github.io.git/raw/master/source/_posts/Spark-standalone环境部署.md"> Source </a>
                            </div>
                            <div class="article-meta-button">
                                <a target="_blank" rel="external nofollow noopener noreferrer" href="https://github.com/weichunxiu123/git@github.com:weichunxiu123/weichunxiu123.github.io.git/edit/master/source/_posts/Spark-standalone环境部署.md"> Edit </a>
                            </div>
                            <div class="article-meta-button">
                                <a target="_blank" rel="external nofollow noopener noreferrer" href="https://github.com/weichunxiu123/git@github.com:weichunxiu123/weichunxiu123.github.io.git/commits/master/source/_posts/Spark-standalone环境部署.md"> History </a>
                            </div>
                        
                    </div>
                
                
    
        <h1 class="article-title" itemprop="name">
            Spark-standalone环境部署
        </h1>
    

            </header>
        
        
        <div class="article-entry" itemprop="articleBody">
        
        
            
                <div id="toc" class="toc-article">
                <strong class="toc-title">Catalogue</strong>
                    <ol class="toc"><li class="toc-item toc-level-2"><a class="toc-link" href="#spark%EF%BC%88StandAlone%E7%8E%AF%E5%A2%83%E9%83%A8%E7%BD%B2%EF%BC%89"><span class="toc-number">1.</span> <span class="toc-text">spark（StandAlone环境部署）</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%8F%82%E8%80%83%E8%B5%84%E6%96%99"><span class="toc-number">2.</span> <span class="toc-text">参考资料</span></a></li></ol>
                </div>
            
        
        
            <h2 id="spark（StandAlone环境部署）"><a href="#spark（StandAlone环境部署）" class="headerlink" title="spark（StandAlone环境部署）"></a><strong>spark（StandAlone环境部署）</strong></h2><p>（一）、集群规划：选择三台机器分别为node1、node2、node3来组成集群环境。</p>
<p>其中node1上安装master和worker进程；node2上安装worker进程；node3上安装worker进程。</p>
<p>（二）、anaconda on linux安装过程：</p>
<p>（1）前提：在linux服务器node1、node2、node3上都安装python(anaconda)。并安装pyspark虚拟环境。具体安装步骤如下。</p>
<p>1、在&#x2F;export&#x2F;server&#x2F;目录下上传anaconda的安装包Anaconda3-2021.05-Linux-x86_64.sh。</p>
<img src="/wiki/Spark-standalone%E7%8E%AF%E5%A2%83%E9%83%A8%E7%BD%B2/wps1.jpg" alt="img" style="zoom:100%;"> 

<img src="/wiki/Spark-standalone%E7%8E%AF%E5%A2%83%E9%83%A8%E7%BD%B2/wps2.jpg" alt="img" style="zoom:100%;"> 

 

<p>2、安装anaconda 使用命令：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sh ./Anaconda3-2021.05-Linux-x86_64.sh</span><br></pre></td></tr></table></figure>

<p><img src="/wiki/Spark-standalone%E7%8E%AF%E5%A2%83%E9%83%A8%E7%BD%B2/wps3.jpg" alt="img" style="zoom:110%;"> <img src="/wiki/Spark-standalone%E7%8E%AF%E5%A2%83%E9%83%A8%E7%BD%B2/wps4.jpg" alt="img" style="zoom:110%;"></p>
<img src="/wiki/Spark-standalone%E7%8E%AF%E5%A2%83%E9%83%A8%E7%BD%B2/wps5.jpg" alt="img" style="zoom:100%;"> 

 

<p>3、安装完毕之后若没有出现base环境，进行如下配置。在&#x2F;root&#x2F;.condarc添加国内源</p>
<img src="/wiki/Spark-standalone%E7%8E%AF%E5%A2%83%E9%83%A8%E7%BD%B2/wps6.jpg" alt="img" style="zoom:110%;"> 

<p>安装完毕后，关闭服务器重新启动，出现base环境即安装成功。</p>
<img src="/wiki/Spark-standalone%E7%8E%AF%E5%A2%83%E9%83%A8%E7%BD%B2/wps7.jpg" alt="img" style="zoom:110%;"> 

 

<p>（2）在anaconda中，安装pyspark虚拟环境。</p>
<p>1、基于python3.8安装pyspark环境。</p>
<img src="/wiki/Spark-standalone%E7%8E%AF%E5%A2%83%E9%83%A8%E7%BD%B2/wps8.jpg" alt="img" style="zoom:110%;"> 

<p>2、切换到pyspark中，并安装所需要的安装包。</p>
<img src="/wiki/Spark-standalone%E7%8E%AF%E5%A2%83%E9%83%A8%E7%BD%B2/wps9.jpg" alt="img" style="zoom:110%;"> 

<p>注：在node1、node2、node3三台服务器上都完成配置！</p>
<p>（三）、StandAlone模式部署</p>
<p>（1）安装spark压缩文件。</p>
<p>1、进入到&#x2F;export&#x2F;server&#x2F;中上传并解压spark-3.2.0-bin-hadoop3.2.tgz。并设置软链接，命令为</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ln-s/export/server/spark-3.2.0-bin-hadoop3.2 /export/server/spark。</span><br></pre></td></tr></table></figure>

<p>（2）在&#x2F;export&#x2F;server&#x2F;spark&#x2F;conf，配置文件。</p>
<p>1、首先在配置workers文件。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">mv workers.template workers</span><br><span class="line">vim workers</span><br></pre></td></tr></table></figure>

<img src="/wiki/Spark-standalone%E7%8E%AF%E5%A2%83%E9%83%A8%E7%BD%B2/wps10.jpg" alt="img" style="zoom:110%;"> 

<p>2.配置spark-env.sh文件。mv spark-env.sh.template spark-env.sh；</p>
<p>Vim spark-env.sh，添加如下内容。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line">## 设置JAVA安装目录</span><br><span class="line">JAVA_HOME=/export/server/jdk</span><br><span class="line">\## HADOOP软件配置文件目录，读取HDFS上文件和运行YARN集群</span><br><span class="line">HADOOP_CONF_DIR=/export/server/hadoop/etc/hadoop</span><br><span class="line">YARN_CONF_DIR=/export/server/hadoop/etc/hadoop</span><br><span class="line">\## 指定spark老大Master的IP和提交任务的通信端口</span><br><span class="line">\# 告知Spark的master运行在哪个机器上</span><br><span class="line">export SPARK_MASTER_HOST=node1</span><br><span class="line">\# 告知sparkmaster的通讯端口</span><br><span class="line">export SPARK_MASTER_PORT=7077</span><br><span class="line">\# 告知spark master的 webui端口</span><br><span class="line">SPARK_MASTER_WEBUI_PORT=8080</span><br><span class="line">\# worker cpu可用核数</span><br><span class="line">SPARK_WORKER_CORES=1</span><br><span class="line">\# worker可用内存</span><br><span class="line">SPARK_WORKER_MEMORY=1g</span><br><span class="line">\# worker的工作通讯地址</span><br><span class="line">SPARK_WORKER_PORT=7078</span><br><span class="line">\# worker的 webui地址</span><br><span class="line">SPARK_WORKER_WEBUI_PORT=8081</span><br><span class="line">\## 设置历史服务器</span><br><span class="line">\# 配置的意思是  将spark程序运行的历史日志 存到hdfs的/sparklog文件夹中</span><br><span class="line">SPARK_HISTORY_OPTS=&quot;-Dspark.history.fs.logDirectory=hdfs://node1:8020/sparklog/ -Dspark.history.fs.cleaner.enabled=true&quot;</span><br></pre></td></tr></table></figure>

<img src="/wiki/Spark-standalone%E7%8E%AF%E5%A2%83%E9%83%A8%E7%BD%B2/wps11.jpg" alt="img" style="zoom:110%;"> 

 

<p>3、在HDFS上创建程序运行历史记录存放的文件夹。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hadoop fs -mkdir /sparklog；hadoop fs -chmod 777 /sparklog</span><br></pre></td></tr></table></figure>

<p>4、配置spark-defaults.conf文件。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">mv spark-defaults.conf.template spark-defaults.conf</span><br><span class="line">vim spark-defaults.conf</span><br></pre></td></tr></table></figure>

<p>添加如下内容。</p>
<img src="/wiki/Spark-standalone%E7%8E%AF%E5%A2%83%E9%83%A8%E7%BD%B2/wps12.jpg" alt="img" style="zoom:110%;">

<p>5、配置log4j.properties 文件[可选配置]。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">mv log4j.properties.template log4j.properties</span><br></pre></td></tr></table></figure>

<p>修改配置，设置级别为WARN 只输出警告和错误日志。</p>
<img src="/wiki/Spark-standalone%E7%8E%AF%E5%A2%83%E9%83%A8%E7%BD%B2/wps13.jpg" alt="img" style="zoom:110%;"> 

 

<p>（四）、将spark分发到node2和node3服务器上。注意同时要设置软链接。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">scp -r spark-3.1.2-bin-hadoop3.2 node2:/export/server/</span><br><span class="line">scp -r spark-3.1.2-bin-hadoop3.2 node3:/export/server/</span><br><span class="line">ln -s /export/server/spark-3.1.2-bin-hadoop3.2 /export/server/spark</span><br></pre></td></tr></table></figure>

<p>注意：配置&#x2F;etc&#x2F;profile，JAVA_HOME；SPARK_HOME；PYSPARK_PYTHON都指向正确的目录。</p>
<p>（五）、启动历史服务器，启动Spark的Master和Worker进程</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">（1）启动历史服务器：sbin/start-history-server.sh</span><br><span class="line">（2）启动全部的master和worker：sbin/start-all.Sh</span><br></pre></td></tr></table></figure>

<img src="/wiki/Spark-standalone%E7%8E%AF%E5%A2%83%E9%83%A8%E7%BD%B2/wps14.jpg" alt="img" style="zoom:110%;"> 

<p><img src="/wiki/Spark-standalone%E7%8E%AF%E5%A2%83%E9%83%A8%E7%BD%B2/wps15.jpg" alt="img" style="zoom:100%;"><img src="/wiki/Spark-standalone%E7%8E%AF%E5%A2%83%E9%83%A8%E7%BD%B2/wps16.jpg" alt="img" style="zoom:100%;"> </p>
<p>（六）、查看Master的WEB UI 在浏览器中输入node1:8080</p>
<img src="/wiki/Spark-standalone%E7%8E%AF%E5%A2%83%E9%83%A8%E7%BD%B2/wps17.jpg" alt="img" style="zoom:100%;"> 

<p>（七）、连接到StandAlone集群</p>
<p>（1）通过master来连接到StandAlone集群。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">bin/pyspark --master spark://node1:7077</span><br></pre></td></tr></table></figure>

<img src="/wiki/Spark-standalone%E7%8E%AF%E5%A2%83%E9%83%A8%E7%BD%B2/wps18.jpg" alt="img" style="zoom:110%;"> 

<p>（2）使用spark-shell连接StandAlone集群。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">bin/spark-shell –master spark://node1:7077</span><br></pre></td></tr></table></figure>

<p>进行测试。</p>
<img src="/wiki/Spark-standalone%E7%8E%AF%E5%A2%83%E9%83%A8%E7%BD%B2/wps19.jpg" alt="img" style="zoom:110%;"> 

<p>（3）使用spark-submit(PI)提交任务到集群上执行。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">bin/spark-submit –master spark://node1:7077/export/server/spark/examples/src/main/Python/pi.py 10</span><br></pre></td></tr></table></figure>

<img src="/wiki/Spark-standalone%E7%8E%AF%E5%A2%83%E9%83%A8%E7%BD%B2/wps20.jpg" alt="img" style="zoom:110%;">

<img src="/wiki/Spark-standalone%E7%8E%AF%E5%A2%83%E9%83%A8%E7%BD%B2/wps21.jpg" alt="img" style="zoom:110%;"> 

<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">查看历史服务器：在浏览器中输入node1：18080</span><br></pre></td></tr></table></figure>

<img src="/wiki/Spark-standalone%E7%8E%AF%E5%A2%83%E9%83%A8%E7%BD%B2/wps22.jpg" alt="img" style="zoom:110%;">

<h2 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h2><blockquote>
<ul>
<li>[1]spark(standalone部署文档)</li>
<li>[2]1-spark基础入门.pdf</li>
</ul>
</blockquote>

            </div>
        
        <footer class="article-footer">
        </footer>
    </div>
</article>


    
<nav id="article-nav">
    
        <a href="/wiki/spark-HA%E7%8E%AF%E5%A2%83%E9%83%A8%E7%BD%B2/" id="article-nav-newer" class="article-nav-link-wrap">
            <strong class="article-nav-caption">Newer</strong>
            <div class="article-nav-title">
                
                    spark-HA环境部署
                
            </div>
        </a>
    
    
        <a href="/wiki/Spark-local%E6%A8%A1%E5%BC%8F%E9%85%8D%E7%BD%AE/" id="article-nav-older" class="article-nav-link-wrap">
            <strong class="article-nav-caption">Older</strong>
            <div class="article-nav-title">Spark--local模式配置</div>
        </a>
    
</nav>





    
    




<!-- baidu url auto push script -->
<script type="text/javascript">
    !function(){var e=/([http|https]:\/\/[a-zA-Z0-9\_\.]+\.baidu\.com)/gi,r=window.location.href,o=document.referrer;if(!e.test(r)){var n="//api.share.baidu.com/s.gif";o?(n+="?r="+encodeURIComponent(document.referrer),r&&(n+="&l="+r)):r&&(n+="?l="+r);var t=new Image;t.src=n}}(window);
</script>     
</section>
        </div>
        <footer id="footer">
    <div class="outer">
        <div id="footer-info" class="inner">
            John Doe &copy; 2023 
            <a rel="external nofollow noopener noreferrer" target="_blank" href="http://creativecommons.org/licenses/by-nc-nd/4.0/"><img alt="Creative Commons License" style="border-width:0" src="https://i.creativecommons.org/l/by-nc-nd/4.0/80x15.png"></a>
            <br> Powered by <a href="http://hexo.io/" target="_blank" rel="external nofollow noopener noreferrer">Hexo</a>. Theme - <a target="_blank" rel="external nofollow noopener noreferrer" href="https://github.com/zthxxx/hexo-theme-Wikitten">wikitten</a>
            
                <br>
                <span id="busuanzi_container_site_pv"><i class="fa fa-eye"></i> <span id="busuanzi_value_site_pv"></span></span>
                &nbsp;|&nbsp;
                <span id="busuanzi_container_site_pv"><i class="fa fa-user"></i> <span id="busuanzi_value_site_uv"></span></span>
            
        </div>
    </div>
</footer>

        

    
        
<script src="/libs/lightgallery/js/lightgallery.min.js"></script>

        
<script src="/libs/lightgallery/js/lg-thumbnail.min.js"></script>

        
<script src="/libs/lightgallery/js/lg-pager.min.js"></script>

        
<script src="/libs/lightgallery/js/lg-autoplay.min.js"></script>

        
<script src="/libs/lightgallery/js/lg-fullscreen.min.js"></script>

        
<script src="/libs/lightgallery/js/lg-zoom.min.js"></script>

        
<script src="/libs/lightgallery/js/lg-hash.min.js"></script>

        
<script src="/libs/lightgallery/js/lg-share.min.js"></script>

        
<script src="/libs/lightgallery/js/lg-video.min.js"></script>

    
    
        
<script src="/libs/justified-gallery/jquery.justifiedGallery.min.js"></script>

    
    
        <script type="text/x-mathjax-config">
    MathJax.Hub.Config({
        tex2jax: {
            inlineMath: [ ["$","$"], ["\\(","\\)"] ],
            skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code'],
            processEscapes: true,
            TeX: {
                equationNumbers: {
                  autoNumber: 'AMS'
                }
            }
        }
    });
    MathJax.Hub.Queue(function() {
        var all = MathJax.Hub.getAllJax();
        for (var i = 0; i < all.length; ++i)
            all[i].SourceElement().parentNode.className += ' has-jax';
    });
</script>
<script async src="//cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
    



<!-- Custom Scripts -->

<script src="/js/main.js"></script>


    </div>
</body>
</html>